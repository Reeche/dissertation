{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import operator\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from random import choice\n",
    "from collections import defaultdict, Counter\n",
    "from analysis_utils import get_data\n",
    "from learning_utils import pickle_load, pickle_save, construct_pipeline, Participant, get_normalized_features,\\\n",
    "                            get_normalized_feature_values, construct_reward_function, reward_levels, reward_type, \\\n",
    "                            construct_repeated_pipeline, create_dir, get_strategy_counts, get_cluster_dict, \\\n",
    "                            get_modified_weights\n",
    "from sequence_utils import compute_average_click_likelihoods\n",
    "from generic_mouselab import GenericMouselabEnv\n",
    "from modified_mouselab import TrialSequence, reward_val, normal_reward_val, constant_reward_val, decreasing_reward_val\n",
    "from planning_strategies import strategy_dict\n",
    "from computational_microscope import ComputationalMicroscope\n",
    "from statsmodels.stats.proportion import proportions_ztest, proportions_chisquare\n",
    "from scipy.stats import ttest_ind, pearsonr\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "import numpy.linalg as LA\n",
    "from scipy.special import softmax\n",
    "from IPython.core.display import display, HTML\n",
    "from experiment_utils import Experiment\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "plt.rcParams[\"axes.grid\"] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_pipelines = pickle_load(\"data/exp_pipelines.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_map = pickle_load(\"data/non_problematic_clusters.pkl\")\n",
    "strategy_space = pickle_load(\"data/strategy_space.pkl\")\n",
    "num_simulations = 1000000\n",
    "exp_nums = [\"v1.0\", \"c1.1\", \"c2.1_dec\", \"T1.1\"]\n",
    "cluster_scores = defaultdict(lambda: defaultdict(list))\n",
    "sq_num = np.sqrt(num_simulations)\n",
    "for exp_num in exp_nums:\n",
    "    for i, strategy in enumerate(strategy_space):\n",
    "        #scores = []\n",
    "        #for sim_num in range(num_simulations):\n",
    "            #pipeline = exp_pipelines[exp_num]\n",
    "            #env = GenericMouselabEnv(num_trials=1, pipeline=pipeline)\n",
    "            #clicks = strategy_dict[strategy](env.present_trial)\n",
    "            #score = env.present_trial.node_map[0].calculate_max_expected_return()\n",
    "        scores = pickle_load(f\"results/strategy_scores/{exp_num}_{strategy-1}_{num_simulations}.pkl\")\n",
    "        cluster_scores[exp_num][cluster_map[i]] += scores\n",
    "            #scores.append(score)\n",
    "        #strategy_scores[exp_num][strategy] = np.mean(scores)\n",
    "        #ses[exp_num][strategy] = np.std(scores)/sq_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<function <lambda> at 0x131c15d90>, {'v1.0': defaultdict(<class 'int'>, {1: 45.3509515, 13: 39.07208152941176, 2: 44.740447333333336, 5: 43.953171, 4: 42.8158216, 6: 45.334842, 10: 32.1941794, 9: 40.9726212, 8: 23.3076252, 7: 7.7588855, 12: 42.95862, 3: 45.333334, 11: 43.989014}), 'c1.1': defaultdict(<class 'int'>, {1: 15.31393875, 13: 11.521002647058824, 2: 14.837128333333334, 5: 13.028325416666666, 4: 13.663711, 6: 15.323355, 10: 7.611349, 9: 8.9220925, 8: 9.755022, 7: 4.32497, 12: 9.298125, 3: 15.314405, 11: 11.976385}), 'c2.1_dec': defaultdict(<class 'int'>, {1: 34.713887, 13: 17.92356882352941, 2: 34.723348, 5: 32.520463666666664, 4: 34.2769104, 6: 34.746704, 10: 6.3481536, 9: 7.2239004, 8: 32.2432862, 7: 12.6630225, 12: 3.582558, 3: 34.72159, 11: 26.34684}), 'T1.1': defaultdict(<class 'int'>, {1: 60.217841998971785, 13: 49.097594323838706, 2: 60.007273986499, 5: 58.87793543462781, 4: 56.88184299472494, 6: 60.20287201866427, 10: 35.75336234825199, 9: 49.45340748548768, 8: 27.906029485515017, 7: 9.555992040599637, 12: 57.866823723029654, 3: 58.58140250020923, 11: 58.244182412966474})})\n"
     ]
    }
   ],
   "source": [
    "cluster_mean_scores = defaultdict(lambda: defaultdict(int))\n",
    "cluster_ses = defaultdict(lambda: defaultdict(int))\n",
    "for exp_num in exp_nums:\n",
    "    for c in cluster_scores[exp_num]:\n",
    "        cluster_mean_scores[exp_num][c] = np.mean(cluster_scores[exp_num][c])\n",
    "        cluster_ses[exp_num][c] = np.std(cluster_scores[exp_num][c])/len(cluster_scores[exp_num][c])\n",
    "print(cluster_mean_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 [1, 8, 9, 13]\n",
      "2 [3, 10, 82]\n",
      "3 [72]\n",
      "4 [5, 36, 37, 54, 79]\n",
      "5 [4, 6, 7, 11, 12, 31, 45, 46, 47, 59, 60, 84]\n",
      "6 [15]\n",
      "7 [28, 30, 34, 66]\n",
      "8 [22, 23, 32, 33, 53, 64, 65, 69, 70, 80]\n",
      "9 [21, 40, 41, 43, 55, 56, 57, 58, 63, 67]\n",
      "10 [16, 26, 27, 29, 44, 50, 61, 73, 78, 89]\n",
      "11 [75]\n",
      "12 [51]\n",
      "13 [2, 14, 17, 18, 24, 39, 42, 48, 49, 62, 71, 74, 76, 85, 86, 87, 88]\n"
     ]
    }
   ],
   "source": [
    "reverse_cluster_map = defaultdict(list)\n",
    "for i, strategy in enumerate(strategy_space):\n",
    "    reverse_cluster_map[cluster_map[i]].append(strategy)\n",
    "for k in sorted(list(reverse_cluster_map.keys())):\n",
    "    print(k, reverse_cluster_map[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_names = [\"Goal setting\", \"Forward planning strategies similar to Breadth First Search\", \"Middle-out planning\", \"Forward planning strategies similar to Best First Search\", \"Local-search strategies\", \"Maximizing goal-setting with exhaustive backward planning\", \"Frugal planning strategies\", \"Myopic planning strategies\", \"Maximizing goal-setting without backward planning\", \"Frugal goal-setting\", \"Strategy that explores immediate outcomes on the paths to the best final outcomes\", \"Strategy that explores immediate rewards on the paths to the best final outcomes with satisficing\", \"Other strategies\"]\n",
    "pickle_save(cluster_names, \"data/cluster_names.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Increasing variance\n",
      "Goal setting 45.3509515 +- 3.4122744892945663e-06\n",
      "Maximizing goal-setting with exhaustive backward planning 45.334842 +- 1.3678780385510836e-05\n",
      "Middle-out planning 45.333334 +- 1.3664721308700154e-05\n",
      "Forward planning strategies similar to Breadth First Search 44.740447333333336 +- 4.51182821300765e-06\n",
      "Strategy that explores immediate outcomes on the paths to the best final outcomes 43.989014 +- 1.2462318697088597e-05\n",
      "Local-search strategies 43.953171 +- 1.1590125438060254e-06\n",
      "Strategy that explores immediate rewards on the paths to the best final outcomes with satisficing 42.95862 +- 1.2606465313306499e-05\n",
      "Forward planning strategies similar to Best First Search 42.8158216 +- 3.349476978377212e-06\n",
      "Maximizing goal-setting without backward planning 40.9726212 +- 1.3927737447313914e-06\n",
      "Other strategies 39.07208152941176 +- 1.0845443019193668e-06\n",
      "Frugal goal-setting 32.1941794 +- 1.9333459710062657e-06\n",
      "Myopic planning strategies 23.3076252 +- 2.2175691473690854e-06\n",
      "Frugal planning strategies 7.7588855 +- 3.913613793524866e-06\n",
      "\n",
      "\n",
      "Constant Variance\n",
      "Maximizing goal-setting with exhaustive backward planning 15.323355 +- 9.072996558137504e-06\n",
      "Middle-out planning 15.314405 +- 9.07792787457441e-06\n",
      "Goal setting 15.31393875 +- 2.269312756806128e-06\n",
      "Forward planning strategies similar to Breadth First Search 14.837128333333334 +- 3.0054524122408157e-06\n",
      "Forward planning strategies similar to Best First Search 13.663711 +- 1.8564112336277106e-06\n",
      "Local-search strategies 13.028325416666666 +- 7.274081640875895e-07\n",
      "Strategy that explores immediate outcomes on the paths to the best final outcomes 11.976385 +- 7.22951086393644e-06\n",
      "Other strategies 11.521002647058824 +- 4.643264275999966e-07\n",
      "Myopic planning strategies 9.755022 +- 7.812825723098913e-07\n",
      "Strategy that explores immediate rewards on the paths to the best final outcomes with satisficing 9.298125 +- 7.291995370567304e-06\n",
      "Maximizing goal-setting without backward planning 8.9220925 +- 3.800164196642529e-07\n",
      "Frugal goal-setting 7.611349 +- 7.380424879381874e-07\n",
      "Frugal planning strategies 4.32497 +- 1.5714557740973018e-06\n",
      "\n",
      "\n",
      "Decreasing variance\n",
      "Maximizing goal-setting with exhaustive backward planning 34.746704 +- 2.4960757222816454e-05\n",
      "Forward planning strategies similar to Breadth First Search 34.723348 +- 8.327431525703752e-06\n",
      "Middle-out planning 34.72159 +- 2.499434031679772e-05\n",
      "Goal setting 34.713887 +- 6.246060845401041e-06\n",
      "Forward planning strategies similar to Best First Search 34.2769104 +- 4.9862760927584885e-06\n",
      "Local-search strategies 32.520463666666664 +- 2.0044764467883517e-06\n",
      "Myopic planning strategies 32.2432862 +- 2.4453965948796315e-06\n",
      "Strategy that explores immediate outcomes on the paths to the best final outcomes 26.34684 +- 2.2390994574033547e-05\n",
      "Other strategies 17.92356882352941 +- 1.2873138641654847e-06\n",
      "Frugal planning strategies 12.6630225 +- 4.964618050291568e-06\n",
      "Maximizing goal-setting without backward planning 7.2239004 +- 1.2467657286390252e-06\n",
      "Frugal goal-setting 6.3481536 +- 1.1607223796877835e-06\n",
      "Strategy that explores immediate rewards on the paths to the best final outcomes with satisficing 3.582558 +- 1.0191654314369182e-06\n",
      "\n",
      "\n",
      "Transfer task\n",
      "Goal setting 60.217841998971785 +- 4.5113941097523154e-06\n",
      "Maximizing goal-setting with exhaustive backward planning 60.20287201866427 +- 1.804817268628065e-05\n",
      "Forward planning strategies similar to Breadth First Search 60.007273986499 +- 5.954549429111338e-06\n",
      "Local-search strategies 58.87793543462781 +- 1.5181566087403467e-06\n",
      "Middle-out planning 58.58140250020923 +- 1.7332394211800697e-05\n",
      "Strategy that explores immediate outcomes on the paths to the best final outcomes 58.244182412966474 +- 1.7092153165669684e-05\n",
      "Strategy that explores immediate rewards on the paths to the best final outcomes with satisficing 57.866823723029654 +- 1.6570931963581305e-05\n",
      "Forward planning strategies similar to Best First Search 56.88184299472494 +- 4.182864811914342e-06\n",
      "Maximizing goal-setting without backward planning 49.45340748548768 +- 2.1649390657966565e-06\n",
      "Other strategies 49.097594323838706 +- 1.5489148910018942e-06\n",
      "Frugal goal-setting 35.75336234825199 +- 2.572866548775124e-06\n",
      "Myopic planning strategies 27.906029485515017 +- 2.8401936486312472e-06\n",
      "Frugal planning strategies 9.555992040599637 +- 4.863715271617656e-06\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "exp_labels = [\"Increasing variance\", \"Constant Variance\", \"Decreasing variance\", \"Transfer task\"]\n",
    "for exp_label, exp_num in zip(exp_labels, exp_nums):\n",
    "    print(exp_label)\n",
    "    sorted_list = sorted(cluster_mean_scores[exp_num].items(), key=operator.itemgetter(1), reverse=True)\n",
    "    for (c, s) in sorted_list:\n",
    "        print(cluster_names[c-1], s, \"+-\", cluster_ses[exp_num][c])\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.3 64-bit ('cogtut': conda)",
   "language": "python",
   "name": "python37364bitcogtutconda3e89249cb8f1438ca66244f989548773"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
